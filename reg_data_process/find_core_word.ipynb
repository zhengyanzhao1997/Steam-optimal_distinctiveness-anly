{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0ae3af69-7d13-4e4d-9c4a-a782956a9517",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import Doc2Vec\n",
    "import json\n",
    "from PyDictionary import PyDictionary\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "from textblob import TextBlob\n",
    "import inflect\n",
    "p = inflect.engine()\n",
    "dictionary=PyDictionary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "127a325d-5182-4d9c-a3fa-8a46cab5760b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = Doc2Vec.load('./doc2vec_dm1_5/doc2vec_model_dm1_add_5')\n",
    "model2 = Doc2Vec.load('./doc2vec_dm0_5/doc2vec_model_dm0_add_5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b9dbe7bf-9b4f-45f1-8e71-121f2e34a359",
   "metadata": {},
   "outputs": [],
   "source": [
    "class find_model_sim:\n",
    "    def __init__(self,model,vaild_words):\n",
    "        self.model = model\n",
    "        self.wv = model.wv\n",
    "        self.vaild_words = vaild_words\n",
    "        self.word_dict = self.wv.key_to_index\n",
    "        vaild_index = [self.wv.key_to_index[x] for x in vaild_words]\n",
    "        self.vaild_vector = self.wv.vectors[vaild_index]\n",
    "        self.norms = np.linalg.norm(self.vaild_vector, axis=1)\n",
    "\n",
    "    def find_most_sim_word(self,words,topn=None,a=0):\n",
    "        results = []\n",
    "        for word in words:\n",
    "            if word not in self.wv:\n",
    "                continue\n",
    "            dists = np.dot(self.vaild_vector, self.wv[word]) / self.norms / np.linalg.norm(self.wv[word])\n",
    "            sorted_dist = np.argsort(-dists)\n",
    "            scores = dists[sorted_dist]\n",
    "            word_sort = [(self.vaild_words[x],score) for x,score in zip(sorted_dist,scores)]\n",
    "            word_sort = [x for x in word_sort if x[1] > a]\n",
    "            if 'else' in [x[0] for x in word_sort]:\n",
    "                print(word)\n",
    "            if topn:\n",
    "                results.append({'word':word,'sim_word':word_sort[:topn]})\n",
    "            else:\n",
    "                results.append({'word':word,'sim_word':word_sort})\n",
    "        return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0166e10-79fc-4fd7-be56-3b8b03903898",
   "metadata": {},
   "outputs": [],
   "source": [
    "reivew_vaild_words_1000 = []\n",
    "with open('../new_1000.txt','r') as f:\n",
    "    for i in f:\n",
    "        reivew_vaild_words_1000.append(i.strip('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9413c89-0d40-4535-a150-aabffed104f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "reivew_vaild_words_500 = []\n",
    "with open('../new_500_1000.txt','r') as f:\n",
    "    for i in f:\n",
    "        reivew_vaild_words_500.append(i.strip('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "df97447b-ecf8-4db7-aafb-319e296018fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "game_vaild_words_50 = []\n",
    "with open('../new_game_50.txt','r') as f:\n",
    "    for i in f:\n",
    "        game_vaild_words_50.append(i.strip('\\n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "780f0e11-8702-4703-986f-9d604fd6198f",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_word = reivew_vaild_words_1000 + reivew_vaild_words_500 + game_vaild_words_50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "acbab117-2c00-4901-aa01-1aab9092290e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_find = find_model_sim(model1,total_word)\n",
    "model_2_find = find_model_sim(model2,total_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5008ee13-9386-4d73-9731-887ee2ce8dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "be_retrive_vaild_words = reivew_vaild_words_1000 + game_vaild_words_50 + reivew_vaild_words_500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ea4bcb04-614c-422d-b603-e917eb9fc254",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_1_find = find_model_sim(model1,be_retrive_vaild_words)\n",
    "model_2_find = find_model_sim(model2,be_retrive_vaild_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "3389a50e-203d-4761-87bd-98a82978e25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "items = []\n",
    "already_deploy_word = []\n",
    "with open('./core_word_rebuild2.json', 'r') as f:\n",
    "    for i in f:\n",
    "        item = json.loads(i)\n",
    "        title = item['title']\n",
    "        key_words = item['key_word']\n",
    "        already_deploy_word += key_words\n",
    "        key_words = [x for x in key_words if x in mother_vaild_words]\n",
    "        items.append({'title':title,'old_keys':item['key_word'],'new_ori_key':key_words})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "43fa74b3-a82c-431f-8be6-5c310d6fe7aa",
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [01:04<00:00,  3.25s/it]\n"
     ]
    }
   ],
   "source": [
    "items = []\n",
    "already_deploy_word = []\n",
    "with open('./core_word_rebuild2.json', 'r') as f:\n",
    "    for i in f:\n",
    "        item = json.loads(i)\n",
    "        title = item['title']\n",
    "        key_words = item['key_word']\n",
    "        already_deploy_word += key_words\n",
    "        key_words = [x for x in key_words if x in mother_vaild_words]\n",
    "        items.append({'title':title,'old_keys':item['key_word'],'new_ori_key':key_words})\n",
    "\n",
    "        \n",
    "deploy = {}\n",
    "for i in tqdm(items):\n",
    "    new_key_words = []\n",
    "    title = i['title']\n",
    "    new_ori_keys = i['new_ori_key']\n",
    "    add_keys_words1 = model_1_find.find_most_sim_word(new_ori_keys, None, 0.75)\n",
    "    add_keys_words2 = model_2_find.find_most_sim_word(new_ori_keys, None, 0.8)\n",
    "    add_keys_words = add_keys_words1 + add_keys_words2\n",
    "    temp_lists = []\n",
    "    for word_group in add_keys_words:\n",
    "        temp_lists += [x for x in word_group['sim_word'] if (x[0] not in already_deploy_word or x[0] in i['old_keys'])]\n",
    "    temp_lists = sorted(temp_lists,key=lambda x:x[1],reverse=True)\n",
    "\n",
    "    for word in temp_lists:\n",
    "        if word[0] in deploy.keys():\n",
    "            if word[1] >  deploy[word[0]][1]:\n",
    "                deploy[word[0]] = (title,word[1])\n",
    "        else:\n",
    "            deploy[word[0]] = (title,word[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}